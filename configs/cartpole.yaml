# Environment configuration
# env name
env: CartpoleBalance

# contexts for training
train_params:
- polelength: [0.4, 0.6, 0.8, 1., 1.2]
  masspole: [0.75, 1.0, 1.25]
  masscart: [0.25, 0.5, 1.5, 2.5]
  gravity: [8.8, 12.0]
  force_mag: [18.0, 22.0]

# model contexts for testing
test_range:
- polelength: [0.2, 0.5, 0.9, 1.4]
  masspole: [0.7, 0.9, 1.4]
  masscart: [1.5, 2.5]
  gravity: [9.8, 12.8]
  force_mag: [10.0, 15.0]

# normalize input (keep False, gives better generalization performance)
normalize_flag: False

# max len of episode (int/None)
trial_len: 200
# Number of initial trials to fill replay buffer (RandomAgent)
init_trials: 20
# Number of episodes w/ agent actions
num_trials: 20
# Use reward function or not (keep false)
reward_fn: False
target_is_delta: False
replay_buffer_sz: 10000

# Agent configuration
agent_args:
  # how long of the horizon to predict
  horizon: 50
  replan_freq: 1
  max_particles: 20

cem_optim_args:
  alpha: 0.1
  # freq of planning
  replan_freq: 1
  # iters per planning step
  num_iters: 5
  # fraction of pop to keep for next step
  elite_ratio: 0.1
  # how many random samples for mpc
  popsize: 200

dynamics_model_args:
  hidden_dim: 200
  hidden_layers: 3
  ensemble_size: 5
  prop_method: fixed_model
  actv: torch.nn.LeakyReLU

# Dynamics model training config
dynamics_train_args:
  lr: 0.001
  batch_size: 256
  epochs_per_step: 50

  # ratio of validation set
  validation_ratio: 0.05
  # number of epochs to early terminate if loss doesn't decrease by much
  # (for potentially faster training)
  patience: 20
